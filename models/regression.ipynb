{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform, color\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from dataLoader import OrganoidDataset\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import torchvision.models as models\n",
    "\n",
    "from dataLoader import OrganoidDataset\n",
    "#from conv_model import SimpleConvNet\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "params = {'batch_size': 100, # low for testing\n",
    "          'shuffle': True, 'num_workers' : 2}\n",
    "max_epochs = 100\n",
    "\n",
    "figure_path = '../milestoneReport/figures/'\n",
    "#path = '../data/CS231n_Tim_Shan_example_data/'\n",
    "path = '../data/'\n",
    "label_path = '../data/well_summary_A1_e0891BSA_all.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrganoidMultipleDataset(data.Dataset):\n",
    "    'dataset class for microwell organoid images'\n",
    "    def __init__(self, path2files, image_names, Y, mean_sd_dict, transforms=None):\n",
    "        for k, image_name in image_names.items():\n",
    "            assert len(image_name) == len(Y)\n",
    "        self.path = path2files\n",
    "        self.image_names = image_names\n",
    "        self.Y = Y\n",
    "        self.mean_sd_dict = mean_sd_dict\n",
    "        self.transforms = transforms\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    def getXimage(self, index):\n",
    "        all_images_list = []\n",
    "        for day,img_names in self.image_names.items():\n",
    "            print(day, \"   \", index)\n",
    "            \n",
    "            img_name = img_names[index]\n",
    "            img_loc = os.path.join(self.path, img_name)\n",
    "            image = io.imread(img_loc)\n",
    "            mean, sd = self.mean_sd_dict[day]\n",
    "            image = np.true_divide(color.rgb2gray(image) - mean, sd)\n",
    "            all_images_list.append(image)\n",
    "        images = np.array(all_images_list)\n",
    "        return torch.from_numpy(images).float()\n",
    "    def getY(self, index):\n",
    "        Y = self.Y[index]\n",
    "        return torch.from_numpy(np.asarray(self.Y[index], dtype=float)).float()\n",
    "    def __getitem__(self, index):\n",
    "        X = self.getXimage(index)\n",
    "        y = self.getY(index)\n",
    "        if self.transforms is not None:\n",
    "            X = self.transforms(X)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = pd.read_csv('../data_description/A1_A2_C1_filtered_train_v2.csv')\n",
    "validation_labels = pd.read_csv('../data_description/A1_A2_C1_filtered_validation_v2.csv')\n",
    "test_labels = pd.read_csv('../data_description/A1_A2_C1_filtered_test_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter for predict size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = training_labels.query('has_cell_13 == 1')\n",
    "validation_labels = validation_labels.query('has_cell_13 == 1')\n",
    "test_labels = test_labels.query('has_cell_13 == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3952, 60), (476, 60), (478, 60))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels.shape,validation_labels.shape,test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>condition</th>\n",
       "      <th>well_id</th>\n",
       "      <th>day_0</th>\n",
       "      <th>well_label</th>\n",
       "      <th>image_name_0</th>\n",
       "      <th>has_cell_0</th>\n",
       "      <th>hyst2_area_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>image_name_1</th>\n",
       "      <th>...</th>\n",
       "      <th>has_cell_11</th>\n",
       "      <th>hyst2_area_11</th>\n",
       "      <th>day_12</th>\n",
       "      <th>image_name_12</th>\n",
       "      <th>has_cell_12</th>\n",
       "      <th>hyst2_area_12</th>\n",
       "      <th>day_13</th>\n",
       "      <th>image_name_13</th>\n",
       "      <th>has_cell_13</th>\n",
       "      <th>hyst2_area_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>well_A1/well0064_day00_well.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>well_A1/well0064_day01_well.png</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>well_A1/well0064_day12_well.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>well_A1/well0064_day13_well.png</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A2</td>\n",
       "      <td>977</td>\n",
       "      <td>0</td>\n",
       "      <td>977</td>\n",
       "      <td>well_A2/well0977_day00_well.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2568</td>\n",
       "      <td>1</td>\n",
       "      <td>well_A2/well0977_day01_well.png</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3227</td>\n",
       "      <td>12</td>\n",
       "      <td>well_A2/well0977_day12_well.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3063</td>\n",
       "      <td>13</td>\n",
       "      <td>well_A2/well0977_day13_well.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 condition  well_id  day_0  well_label  \\\n",
       "0           0        A1       64      0          64   \n",
       "2           2        A2      977      0         977   \n",
       "\n",
       "                      image_name_0  has_cell_0  hyst2_area_0  day_1  \\\n",
       "0  well_A1/well0064_day00_well.png           0             0      1   \n",
       "2  well_A2/well0977_day00_well.png           1          2568      1   \n",
       "\n",
       "                      image_name_1  ...  has_cell_11  hyst2_area_11  day_12  \\\n",
       "0  well_A1/well0064_day01_well.png  ...            0              0      12   \n",
       "2  well_A2/well0977_day01_well.png  ...            1           3227      12   \n",
       "\n",
       "                     image_name_12  has_cell_12  hyst2_area_12  day_13  \\\n",
       "0  well_A1/well0064_day12_well.png            0              0      13   \n",
       "2  well_A2/well0977_day12_well.png            1           3063      13   \n",
       "\n",
       "                     image_name_13  has_cell_13  hyst2_area_13  \n",
       "0  well_A1/well0064_day13_well.png            1            172  \n",
       "2  well_A2/well0977_day13_well.png            1           3194  \n",
       "\n",
       "[2 rows x 60 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_names = {2:training_labels['image_name_2'],8:training_labels['image_name_8'], 5:training_labels['image_name_5']}\n",
    "validation_image_names = {2:validation_labels['image_name_2'],8:validation_labels['image_name_8'],5:validation_labels['image_name_5']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_y = training_labels['hyst2_area_13']\n",
    "validation_y = validation_labels['hyst2_area_13']\n",
    "#test_y = test_labels['hyst2_area_13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sd_dict = {2: [0.49439774802337344, 0.16087996922691195],\n",
    " 8: [0.5177020917650417, 0.15714445907773483],\n",
    " 5: [0.5013496452715945, 0.1605951051365687],              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = OrganoidMultipleDataset(path2files = path, image_names = training_image_names, Y = training_labels['has_cell_13'],mean_sd_dict=mean_sd_dict)\n",
    "validation_set = OrganoidMultipleDataset(path2files = path, image_names = validation_image_names, Y = validation_labels['has_cell_13'],mean_sd_dict=mean_sd_dict)\n",
    "#test_set = OrganoidMultipleDataset(path2files = path, image_names = test_image_names, Y = test_labels['has_cell_13'],mean_sd_dict=mean_sd_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = data.DataLoader(train_set, **params)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "#test_generator = data.DataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening:  tensor([[[[ 0,  1],\n",
      "          [ 2,  3],\n",
      "          [ 4,  5]]],\n",
      "\n",
      "\n",
      "        [[[ 6,  7],\n",
      "          [ 8,  9],\n",
      "          [10, 11]]]])\n",
      "After flattening:  tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print('Before flattening: ', x)\n",
    "    print('After flattening: ', flatten(x))\n",
    "\n",
    "test_flatten()\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model,dataset='validation'):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            val_loss = F.mse_loss(preds, y)\n",
    "            val_error = val_loss.item()\n",
    "            losses.append(val_error)\n",
    "            totalbatchMSE = totalbatchMSE + params['batch_size']*val_error/NUM_VAL\n",
    "        print('Got accuracy (%.2f)' % (100 * val_error))\n",
    "        #print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return totalbatchMSE,preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1,lr_scheduler=None):\n",
    "    best_model = None\n",
    "    best_validation_accuracy = -1\n",
    "    \n",
    "    losses = []\n",
    "    validation_accuracy = []\n",
    "    training_accuracy = []\n",
    "    prediction = []\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        print('epoch:',e)\n",
    "        \n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "            print('LR:', lr_scheduler.get_lr())\n",
    "\n",
    "        for t, (x, y) in enumerate(training_generator):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            Y_hat = model(x)\n",
    "            #loss = nn.MSELoss(Y_hat,y)\n",
    "            loss = F.mse_loss(Y_hat, y)\n",
    "            \n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_error = loss.item()\n",
    "            \n",
    "            totalbatchMSE = totalbatchMSE + params['batch_size']*train_error/NUM_TRAIN\n",
    "            \n",
    "            #losses.append(train_error)\n",
    "            losses[e] =train_error\n",
    "            epoch_error[e] = totalbatchMSE\n",
    "\n",
    "            if t % print_every == 0:\n",
    "\n",
    "                print('Iteration %d, loss = %.4f' % (t, l))\n",
    "                train_acc, _ = check_accuracy_part34(training_generator, model, dataset='training')\n",
    "                training_accuracy.append(train_acc)\n",
    "                validation_acc, preds = check_accuracy_part34(validation_generator, model,dataset='validation')\n",
    "                validation_accuracy.append(validation_acc)\n",
    "                prediction.append(preds)\n",
    "                \n",
    "                if validation_acc > best_validation_accuracy:\n",
    "                    best_validation_accuracy = validation_acc\n",
    "                    best_model = copy.deepcopy(model)\n",
    "\n",
    "\n",
    "                print()\n",
    "\n",
    "        \n",
    "                        \n",
    "#     checkpoint = {'model': best_model,\n",
    "#                 'state_dict': model.state_dict()\n",
    "#                }\n",
    "\n",
    "#     torch.save(checkpoint, 'classification_checkpoint.pth')\n",
    "    #torch.save(best_model.state_dict(), 'classification_model.pth')\n",
    "    return losses, validation_accuracy, training_accuracy, prediction,best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 2 \n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "channel_3 = 8\n",
    "out_size = 1\n",
    "image_size = int(193/2/2)\n",
    "image_size = 193\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=in_channels,out_channels=32,kernel_size=5,padding=2,bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,padding=1,bias=True),\n",
    "    nn.ReLU(), \n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=1,bias=True),\n",
    "    nn.ReLU(),  \n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,padding=1,bias=True),\n",
    "    nn.ReLU(),  \n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,padding=1,bias=True),\n",
    "    nn.ReLU(),  \n",
    "    nn.MaxPool2d(2),\n",
    "    \n",
    "    nn.Dropout(),\n",
    "    Flatten(),\n",
    "    nn.Linear(256*6*6, out_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained Resnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18()\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f342366f7b8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f342366f7b8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f342366f7b8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f342366f7b8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f342366f7b8>\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f342366f7b8>\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "    w.join()\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "KeyError:Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 99, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-29-042cd6044c57>\", line 30, in __getitem__\n    X = self.getXimage(index)\n  File \"<ipython-input-29-042cd6044c57>\", line 18, in getXimage\n    img_name = img_names[index]\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\", line 868, in __getitem__\n    result = self.index.get_value(self, key)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 4375, in get_value\n    tz=getattr(series.dtype, 'tz', None))\n  File \"pandas/_libs/index.pyx\", line 81, in pandas._libs.index.IndexEngine.get_value\n  File \"pandas/_libs/index.pyx\", line 89, in pandas._libs.index.IndexEngine.get_value\n  File \"pandas/_libs/index.pyx\", line 132, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 987, in pandas._libs.hashtable.Int64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 993, in pandas._libs.hashtable.Int64HashTable.get_item\nKeyError: 2340\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-f60b21a41e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-b6d0cdd126a8>\u001b[0m in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, epochs, lr_scheduler)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LR:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# put model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move to device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;31m# a python bug https://bugs.python.org/issue2651\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KeyError:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: KeyError:Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 99, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-29-042cd6044c57>\", line 30, in __getitem__\n    X = self.getXimage(index)\n  File \"<ipython-input-29-042cd6044c57>\", line 18, in getXimage\n    img_name = img_names[index]\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\", line 868, in __getitem__\n    result = self.index.get_value(self, key)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 4375, in get_value\n    tz=getattr(series.dtype, 'tz', None))\n  File \"pandas/_libs/index.pyx\", line 81, in pandas._libs.index.IndexEngine.get_value\n  File \"pandas/_libs/index.pyx\", line 89, in pandas._libs.index.IndexEngine.get_value\n  File \"pandas/_libs/index.pyx\", line 132, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 987, in pandas._libs.hashtable.Int64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 993, in pandas._libs.hashtable.Int64HashTable.get_item\nKeyError: 2340\n"
     ]
    }
   ],
   "source": [
    "print_every = 100\n",
    "epoches = 10\n",
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer =optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses,validation_accuracy, training_accuracy,prediction,best_model = train_part34(model, optimizer,epochs=epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
