{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform, color\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from dataLoader import OrganoidDataset\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from dataLoader import OrganoidDataset\n",
    "#from conv_model import SimpleConvNet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "params = {'batch_size': 100, # low for testing\n",
    "          'shuffle': True, 'num_workers' : 2}\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_path = '../milestoneReport/figures/'\n",
    "path = '../data/CS231n_Tim_Shan_example_data/'\n",
    "label_path = '../data/well_summary_A1_e0891BSA_all.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv(label_path)\n",
    "new_columns = ['well_id','day','median_pixel_intensity','mw_area_shape','hyst1_area','hyst2_area']\n",
    "label.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_name(well_id,day_id):\n",
    "    image_name = 'well'+str(well_id).zfill(4)+'_day'+str(day_id).zfill(2)+'_well.png'\n",
    "    return image_name\n",
    "def get_well_label(well_id):\n",
    "    return str(well_id).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label['image_name'] = label[['well_id','day']].apply(lambda x: get_image_name(*x),axis=1)\n",
    "label['well_label'] = label['well_id'].apply(lambda x: get_well_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_id</th>\n",
       "      <th>day</th>\n",
       "      <th>median_pixel_intensity</th>\n",
       "      <th>mw_area_shape</th>\n",
       "      <th>hyst1_area</th>\n",
       "      <th>hyst2_area</th>\n",
       "      <th>image_name</th>\n",
       "      <th>well_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>512</td>\n",
       "      <td>418</td>\n",
       "      <td>well0000_day00_well.png</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>8265</td>\n",
       "      <td>3044</td>\n",
       "      <td>3008</td>\n",
       "      <td>well0001_day00_well.png</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   well_id  day  median_pixel_intensity  mw_area_shape  hyst1_area  \\\n",
       "0        0    0                   125.0           7830         512   \n",
       "1        1    0                   125.0           8265        3044   \n",
       "\n",
       "   hyst2_area               image_name well_label  \n",
       "0         418  well0000_day00_well.png       0000  \n",
       "1        3008  well0001_day00_well.png       0001  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_labels = label.query(\"mw_area_shape < 32000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "corrected_labels.loc[:,'has_cell'] = np.int64(corrected_labels['hyst2_area'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_description(corrected_labels,day):\n",
    "    df = corrected_labels.query(\"day == %d\"%day)[['well_id','day','well_label','image_name','has_cell']]\n",
    "    day_suffix = '_' + str(day)\n",
    "    df = df.rename(columns={'day':'day'+day_suffix, 'has_cell':'has_cell'+day_suffix,'image_name':'image_name'+day_suffix})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "day2wells = get_day_description(corrected_labels,2)\n",
    "day8wells = get_day_description(corrected_labels,8)\n",
    "day13wells = get_day_description(corrected_labels,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4712, 5), (4642, 5), (4712, 5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day2wells.shape, day8wells.shape, day13wells.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_days = day2wells.merge(day8wells,on=['well_id','well_label']).merge(day13wells,on=['well_id','well_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4510, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_days.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle dataframe\n",
    "merged_days = merged_days.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f56d0b41f60>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f56d0a79358>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f56d0aa06d8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f56d0a47c50>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_days[['has_cell_2','has_cell_8','has_cell_13']].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_id</th>\n",
       "      <th>day_1</th>\n",
       "      <th>well_label</th>\n",
       "      <th>image_name_1</th>\n",
       "      <th>has_cell_1</th>\n",
       "      <th>day_8</th>\n",
       "      <th>image_name_8</th>\n",
       "      <th>has_cell_8</th>\n",
       "      <th>day_13</th>\n",
       "      <th>image_name_13</th>\n",
       "      <th>has_cell_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2725</td>\n",
       "      <td>1</td>\n",
       "      <td>2725</td>\n",
       "      <td>well2725_day01_well.png</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>well2725_day08_well.png</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>well2725_day13_well.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3913</td>\n",
       "      <td>1</td>\n",
       "      <td>3913</td>\n",
       "      <td>well3913_day01_well.png</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>well3913_day08_well.png</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>well3913_day13_well.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   well_id  day_1 well_label             image_name_1  has_cell_1  day_8  \\\n",
       "0     2725      1       2725  well2725_day01_well.png           0      8   \n",
       "1     3913      1       3913  well3913_day01_well.png           1      8   \n",
       "\n",
       "              image_name_8  has_cell_8  day_13            image_name_13  \\\n",
       "0  well2725_day08_well.png           0      13  well2725_day13_well.png   \n",
       "1  well3913_day08_well.png           0      13  well3913_day13_well.png   \n",
       "\n",
       "   has_cell_13  \n",
       "0            0  \n",
       "1            0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_days.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'well1705_day01_well.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(path+image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[139, 139, 139, 255],\n",
       "        [134, 134, 134, 255],\n",
       "        [130, 130, 130, 255],\n",
       "        ...,\n",
       "        [134, 134, 134, 255],\n",
       "        [135, 135, 135, 255],\n",
       "        [128, 128, 128, 255]],\n",
       "\n",
       "       [[134, 134, 134, 255],\n",
       "        [131, 131, 131, 255],\n",
       "        [131, 131, 131, 255],\n",
       "        ...,\n",
       "        [134, 134, 134, 255],\n",
       "        [134, 134, 134, 255],\n",
       "        [130, 130, 130, 255]],\n",
       "\n",
       "       [[131, 131, 131, 255],\n",
       "        [131, 131, 131, 255],\n",
       "        [131, 131, 131, 255],\n",
       "        ...,\n",
       "        [131, 131, 131, 255],\n",
       "        [131, 131, 131, 255],\n",
       "        [130, 130, 130, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[127, 127, 127, 255],\n",
       "        [128, 128, 128, 255],\n",
       "        [128, 128, 128, 255],\n",
       "        ...,\n",
       "        [131, 131, 131, 255],\n",
       "        [130, 130, 130, 255],\n",
       "        [128, 128, 128, 255]],\n",
       "\n",
       "       [[127, 127, 127, 255],\n",
       "        [128, 128, 128, 255],\n",
       "        [130, 130, 130, 255],\n",
       "        ...,\n",
       "        [130, 130, 130, 255],\n",
       "        [128, 128, 128, 255],\n",
       "        [128, 128, 128, 255]],\n",
       "\n",
       "       [[128, 128, 128, 255],\n",
       "        [128, 128, 128, 255],\n",
       "        [128, 128, 128, 255],\n",
       "        ...,\n",
       "        [130, 130, 130, 255],\n",
       "        [130, 130, 130, 255],\n",
       "        [130, 130, 130, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 193, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54509804, 0.5254902 , 0.50980392, ..., 0.5254902 , 0.52941176,\n",
       "        0.50196078],\n",
       "       [0.5254902 , 0.51372549, 0.51372549, ..., 0.5254902 , 0.5254902 ,\n",
       "        0.50980392],\n",
       "       [0.51372549, 0.51372549, 0.51372549, ..., 0.51372549, 0.51372549,\n",
       "        0.50980392],\n",
       "       ...,\n",
       "       [0.49803922, 0.50196078, 0.50196078, ..., 0.51372549, 0.50980392,\n",
       "        0.50196078],\n",
       "       [0.49803922, 0.50196078, 0.50980392, ..., 0.50980392, 0.50196078,\n",
       "        0.50196078],\n",
       "       [0.50196078, 0.50196078, 0.50196078, ..., 0.50980392, 0.50980392,\n",
       "        0.50980392]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color.rgb2gray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_mean_and_var = pd.read_csv('day1_mean_and_var.txt', sep = '\\t', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.504038</td>\n",
       "      <td>0.026985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean  variance\n",
       "0  0.504038  0.026985"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1_mean_and_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = color.rgb2gray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 193)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.reshape(image, newshape = (1, image.shape[0], image.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 193, 193)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_image = torch.from_numpy(image).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5451, 0.5255, 0.5098,  ..., 0.5255, 0.5294, 0.5020],\n",
       "         [0.5255, 0.5137, 0.5137,  ..., 0.5255, 0.5255, 0.5098],\n",
       "         [0.5137, 0.5137, 0.5137,  ..., 0.5137, 0.5137, 0.5098],\n",
       "         ...,\n",
       "         [0.4980, 0.5020, 0.5020,  ..., 0.5137, 0.5098, 0.5020],\n",
       "         [0.4980, 0.5020, 0.5098,  ..., 0.5098, 0.5020, 0.5020],\n",
       "         [0.5020, 0.5020, 0.5020,  ..., 0.5098, 0.5098, 0.5098]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 193)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((image,image2),axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 193, 193)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([image,image2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = {1:merged_days['image_name_1'],8:merged_days['image_name_8']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sd_dict={1:[0.5,0.02],8:[0.5,0.02]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-1db1651f561d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "np.array([]).append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "    all_images_list = []\n",
    "    for day,img_names in image_names.items():\n",
    "        img_name = img_names[index]\n",
    "        img_loc = os.path.join(path, img_name)\n",
    "        image = io.imread(img_loc)\n",
    "        mean, sd = mean_sd_dict[day]\n",
    "        image = np.true_divide(color.rgb2gray(image) - mean, sd)\n",
    "        all_images_list.append(image)\n",
    "    images = np.array(all_images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.25490196,  1.2745098 ,  0.49019608, ...,  1.2745098 ,\n",
       "          1.47058824,  0.09803922],\n",
       "        [ 1.2745098 ,  0.68627451,  0.68627451, ...,  1.2745098 ,\n",
       "          1.2745098 ,  0.49019608],\n",
       "        [ 0.68627451,  0.68627451,  0.68627451, ...,  0.68627451,\n",
       "          0.68627451,  0.49019608],\n",
       "        ...,\n",
       "        [-0.09803922,  0.09803922,  0.09803922, ...,  0.68627451,\n",
       "          0.49019608,  0.09803922],\n",
       "        [-0.09803922,  0.09803922,  0.49019608, ...,  0.49019608,\n",
       "          0.09803922,  0.09803922],\n",
       "        [ 0.09803922,  0.09803922,  0.09803922, ...,  0.49019608,\n",
       "          0.49019608,  0.49019608]],\n",
       "\n",
       "       [[ 2.25490196,  1.8627451 ,  2.25490196, ...,  1.07843137,\n",
       "          1.07843137,  0.29411765],\n",
       "        [ 2.25490196,  1.47058824,  0.68627451, ...,  1.07843137,\n",
       "          1.07843137,  1.07843137],\n",
       "        [ 0.09803922,  0.29411765,  0.09803922, ...,  0.68627451,\n",
       "          0.68627451,  1.47058824],\n",
       "        ...,\n",
       "        [ 1.07843137,  0.29411765,  0.29411765, ...,  2.25490196,\n",
       "          0.68627451,  0.29411765],\n",
       "        [ 0.68627451,  0.29411765,  0.68627451, ...,  1.47058824,\n",
       "          1.47058824,  1.07843137],\n",
       "        [ 0.29411765,  0.29411765,  0.29411765, ...,  1.07843137,\n",
       "          1.07843137,  0.29411765]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 193, 193)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_images).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mean(x, x_bar_prev, n):\n",
    "  return x_bar_prev + (x - x_bar_prev)/n\n",
    "\n",
    "def update_sum_square_diff(x, ssd_prev, x_bar_prev, x_bar_curr):\n",
    "  return ssd_prev + (x - x_bar_prev)*(x - x_bar_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(image_names):\n",
    "    #image_names = merged_days['image_name_1']\n",
    "    x_bar_curr = 0.0\n",
    "    x_bar_prev = 0.0\n",
    "    ssd_curr = 0.0\n",
    "    n = 0\n",
    "    for index in range(len(image_names)):\n",
    "        img_name = image_names[index]\n",
    "        img_loc = os.path.join(path, img_name)\n",
    "      # skimage.io.imread returns a numpy array\n",
    "        image = io.imread(img_loc)\n",
    "      # convert to grey scale\n",
    "        image = color.rgb2gray(image)\n",
    "        for i, x in np.ndenumerate(image):\n",
    "            n = n + 1\n",
    "            x_bar_prev = x_bar_curr\n",
    "            x_bar_curr = update_mean(x, x_bar_prev, n)\n",
    "            ssd_curr = update_sum_square_diff(x, ssd_curr, x_bar_prev, x_bar_curr)\n",
    "    return x_bar_curr, ssd_curr/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026858544900843943"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1_std = ssd_curr/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5030599878198688"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1_mean = x_bar_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sd_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_sd_dict[1] = [day1_mean, day1_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "day8_mean, day8_std = get_mean_std(merged_days['image_name_8'])\n",
    "day2_mean, day2_std = get_mean_std(merged_days['image_name_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sd_dict[2] = [day2_mean, np.sqrt(day2_std)]\n",
    "mean_sd_dict[8] = [day8_mean, np.sqrt(day8_std)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [0.49286571111372995, 0.16116063273637155],\n",
       " 8: [0.5374226001116033, 0.15356177002318155]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sd_df = pd.DataFrame.from_dict(mean_sd_dict,orient='index',columns=['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sd_df.to_csv(\"mean_sd_for_4510images.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrganoidMultipleDataset(data.Dataset):\n",
    "    'dataset class for microwell organoid images'\n",
    "    def __init__(self, path2files, image_names, Y, mean_sd_dict):\n",
    "        for k, image_name in image_names.items():\n",
    "            assert len(image_name) == len(Y)\n",
    "        self.path = path2files\n",
    "        self.image_names = image_names\n",
    "        self.Y = Y\n",
    "        self.mean_sd_dict = mean_sd_dict\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    def getXimage(self, index):\n",
    "        all_images_list = []\n",
    "        for day,img_names in self.image_names.items():\n",
    "            print(image_names.shape[0])\n",
    "            img_name = img_names[index]\n",
    "            img_loc = os.path.join(self.path, img_name)\n",
    "            image = io.imread(img_loc)\n",
    "            mean, sd = self.mean_sd_dict[day]\n",
    "            image = np.true_divide(color.rgb2gray(image) - mean, sd)\n",
    "            all_images_list.append(image)\n",
    "        images = np.array(all_images_list)\n",
    "        return torch.from_numpy(images).float()\n",
    "    def getY(self, index):\n",
    "        Y = self.Y[index]\n",
    "        return torch.from_numpy(np.asarray(self.Y[index], dtype=float)).float()\n",
    "    def __getitem__(self, index):\n",
    "        X = self.getXimage(index)\n",
    "        y = self.getY(index)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels=merged_days[:100]\n",
    "validation_labels = merged_days[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_names = {2:training_labels['image_name_2'],8:training_labels['image_name_8']}\n",
    "validation_image_names = {2:validation_labels['image_name_2'],8:validation_labels['image_name_8']}\n",
    "training_y = training_labels['has_cell_13']\n",
    "validation_y = training_labels['has_cell_13']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sd_dict = {2: [0.49286571111372995, 0.16116063273637155],\n",
    " 8: [0.5374226001116033, 0.15356177002318155]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [0.49286571111372995, 0.16116063273637155],\n",
       " 8: [0.5374226001116033, 0.15356177002318155]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = OrganoidMultipleDataset(path2files = path, image_names = training_image_names, Y = training_labels['has_cell_13'],mean_sd_dict=mean_sd_dict)\n",
    "validation_set = OrganoidMultipleDataset(path2files = path, image_names = validation_image_names, Y = validation_labels['has_cell_13'],mean_sd_dict=mean_sd_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = data.DataLoader(train_set, **params)\n",
    "validation_generator = data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening:  tensor([[[[ 0,  1],\n",
      "          [ 2,  3],\n",
      "          [ 4,  5]]],\n",
      "\n",
      "\n",
      "        [[[ 6,  7],\n",
      "          [ 8,  9],\n",
      "          [10, 11]]]])\n",
      "After flattening:  tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print('Before flattening: ', x)\n",
    "    print('After flattening: ', flatten(x))\n",
    "\n",
    "test_flatten()\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        train_errors = []\n",
    "        validation_accuracy = []\n",
    "        prediction = []\n",
    "        for t, (x, y) in enumerate(training_generator):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            \n",
    "            train_error = loss.item()\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_errors.append(train_error)\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                validation_acc, preds = check_accuracy_part34(validation_generator, model)\n",
    "                validation_accuracy.append(validation_acc)\n",
    "                prediction.append(preds)\n",
    "                print()\n",
    "    return train_errors, validation_accuracy, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 2 \n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "channel_3 = 8\n",
    "out_size = 1\n",
    "image_size = 193\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=in_channels,out_channels=channel_1,kernel_size=5,padding=2,bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=channel_1,out_channels=channel_2,kernel_size=3,padding=1,bias=True),\n",
    "    nn.ReLU(), \n",
    "    nn.Conv2d(in_channels=channel_2,out_channels=channel_2,kernel_size=3,padding=1,bias=True),\n",
    "    nn.ReLU(),  \n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2*image_size*image_size, 2,bias=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 100\n",
    "epoches = 20\n",
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer =optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_errors,val_accuracy,prediction = train_part34(model, optimizer,epochs=epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-33-f698c138feb1>\", line 27, in __getitem__\n",
      "    X = self.getXimage(index)\n",
      "  File \"<ipython-input-33-f698c138feb1>\", line 15, in getXimage\n",
      "    img_name = img_names[index]\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\", line 767, in __getitem__\n",
      "    result = self.index.get_value(self, key)\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3118, in get_value\n",
      "    tz=getattr(series.dtype, 'tz', None))\n",
      "  File \"pandas/_libs/index.pyx\", line 106, in pandas._libs.index.IndexEngine.get_value\n",
      "  File \"pandas/_libs/index.pyx\", line 114, in pandas._libs.index.IndexEngine.get_value\n",
      "  File \"pandas/_libs/index.pyx\", line 162, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 958, in pandas._libs.hashtable.Int64HashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 964, in pandas._libs.hashtable.Int64HashTable.get_item\n",
      "KeyError: 32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( 'Traceback (most recent call last):\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\\n    samples = collate_fn([dataset[i] for i in batch_indices])\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\\n    samples = collate_fn([dataset[i] for i in batch_indices])\\n  File \"<ipython-input-33-f698c138feb1>\", line 27, in __getitem__\\n    X = self.getXimage(index)\\n  File \"<ipython-input-33-f698c138feb1>\", line 15, in getXimage\\n    img_name = img_names[index]\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\", line 767, in __getitem__\\n    result = self.index.get_value(self, key)\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3118, in get_value\\n    tz=getattr(series.dtype, \\'tz\\', None))\\n  File \"pandas/_libs/index.pyx\", line 106, in pandas._libs.index.IndexEngine.get_value\\n  File \"pandas/_libs/index.pyx\", line 114, in pandas._libs.index.IndexEngine.get_value\\n  File \"pandas/_libs/index.pyx\", line 162, in pandas._libs.index.IndexEngine.get_loc\\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 958, in pandas._libs.hashtable.Int64HashTable.get_item\\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 964, in pandas._libs.hashtable.Int64HashTable.get_item\\nKeyError: 32\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
