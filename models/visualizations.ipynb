{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/users/tdaley\n",
      "/oak/stanford/groups/whwong/group_scratch/tdaley/CS231N/OrganoidNet/models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('/oak/stanford/groups/whwong/group_scratch/tdaley/CS231N/OrganoidNet/models/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import io, transform, color\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "import torchvision.models as models\n",
    "import dataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/software/user/open/py-pytorch/1.0.0_py36/lib/python3.6/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/share/software/user/open/py-pytorch/1.0.0_py36/lib/python3.6/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/share/software/user/open/py-pytorch/1.0.0_py36/lib/python3.6/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/share/software/user/open/py-pytorch/1.0.0_py36/lib/python3.6/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/share/software/user/open/py-pytorch/1.0.0_py36/lib/python3.6/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/share/software/user/open/py-pytorch/1.0.0_py36/lib/python3.6/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveAvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/share/software/user/open/py-pytorch/1.0.0_py36/lib/python3.6/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = torch.load('classification_model.pth', map_location='cpu')\n",
    "#class TempModel(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        self.conv1 = nn.Conv2d(3, 5, (3, 3))\n",
    "#    def forward(self, inp):\n",
    "#        return self.conv1(inp)\n",
    "\n",
    "#model = TempModel()\n",
    "#model.load_state_dict(torch.load('classification_model.pth', map_location='cpu'))\n",
    "#model.eval()\n",
    "\n",
    "\n",
    "resnet18 = models.resnet18()\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.load_state_dict(torch.load('classification_checkpoint.pth', map_location='cpu')['state_dict'])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OrganoidMultipleDataset(data.Dataset):\n",
    "    'dataset class for microwell organoid images'\n",
    "    def __init__(self, path2files, image_names, Y, mean_sd_dict, transforms=None):\n",
    "        for k, image_name in image_names.items():\n",
    "            assert len(image_name) == len(Y)\n",
    "        self.path = path2files\n",
    "        self.image_names = image_names\n",
    "        self.Y = Y\n",
    "        self.mean_sd_dict = mean_sd_dict\n",
    "        self.transforms = transforms\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    def getXimage(self, index):\n",
    "        all_images_list = []\n",
    "        for day,img_names in self.image_names.items():\n",
    "            #print(day, \"   \", index)\n",
    "            \n",
    "            img_name = img_names[index]\n",
    "            img_loc = os.path.join(self.path, img_name)\n",
    "            image = io.imread(img_loc)\n",
    "            mean, sd = self.mean_sd_dict[day]\n",
    "            image = np.true_divide(color.rgb2gray(image) - mean, sd)\n",
    "            all_images_list.append(image)\n",
    "        images = np.array(all_images_list)\n",
    "        return torch.from_numpy(images).float()\n",
    "    def getY(self, index):\n",
    "        Y = self.Y[index]\n",
    "        return torch.from_numpy(np.asarray(self.Y[index], dtype=float)).float()\n",
    "    def __getitem__(self, index):\n",
    "        X = self.getXimage(index)\n",
    "        y = self.getY(index)\n",
    "        if self.transforms is not None:\n",
    "            X = self.transforms(X)\n",
    "        return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 condition  well_id  day_0  well_label  \\\n",
      "0        7328        A1      335      0         335   \n",
      "1        7329        A1     1105      0        1105   \n",
      "2        7330        A1     3397      0        3397   \n",
      "3        7331        A1     1684      0        1684   \n",
      "4        7332        C1     1077      0        1077   \n",
      "\n",
      "                      image_name_0  has_cell_0  hyst2_area_0  day_1  \\\n",
      "0  well_A1/well0335_day00_well.png           1          2260      1   \n",
      "1  well_A1/well1105_day00_well.png           1          2104      1   \n",
      "2  well_A1/well3397_day00_well.png           1            75      1   \n",
      "3  well_A1/well1684_day00_well.png           0             0      1   \n",
      "4  well_C1/well1077_day00_well.png           0             0      1   \n",
      "\n",
      "                      image_name_1      ...        has_cell_11  hyst2_area_11  \\\n",
      "0  well_A1/well0335_day01_well.png      ...                  0              0   \n",
      "1  well_A1/well1105_day01_well.png      ...                  0              0   \n",
      "2  well_A1/well3397_day01_well.png      ...                  0              0   \n",
      "3  well_A1/well1684_day01_well.png      ...                  1           1913   \n",
      "4  well_C1/well1077_day01_well.png      ...                  0              0   \n",
      "\n",
      "   day_12                    image_name_12  has_cell_12  hyst2_area_12  \\\n",
      "0      12  well_A1/well0335_day12_well.png            0              0   \n",
      "1      12  well_A1/well1105_day12_well.png            0              0   \n",
      "2      12  well_A1/well3397_day12_well.png            0              0   \n",
      "3      12  well_A1/well1684_day12_well.png            1           2032   \n",
      "4      12  well_C1/well1077_day12_well.png            0              0   \n",
      "\n",
      "   day_13                    image_name_13  has_cell_13  hyst2_area_13  \n",
      "0      13  well_A1/well0335_day13_well.png            1            577  \n",
      "1      13  well_A1/well1105_day13_well.png            1            165  \n",
      "2      13  well_A1/well3397_day13_well.png            0              0  \n",
      "3      13  well_A1/well1684_day13_well.png            1           2465  \n",
      "4      13  well_C1/well1077_day13_well.png            0              0  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "(815, 60)\n",
      "(815,)\n"
     ]
    }
   ],
   "source": [
    "test_labels = pd.read_csv('../data_description/A1_A2_C1_filtered_test_v2.csv')\n",
    "print(test_labels.head())\n",
    "print(test_labels.shape)\n",
    "test_image_names = {2:test_labels['image_name_2'],8:test_labels['image_name_8'],5:test_labels['image_name_5']}\n",
    "test_y = test_labels['has_cell_13']\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_sd_dict = {2: [0.49439774802337344, 0.16087996922691195],\n",
    " 8: [0.5177020917650417, 0.15714445907773483],\n",
    " 5: [0.5013496452715945, 0.1605951051365687],              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../data/14day/'\n",
    "test_set = OrganoidMultipleDataset(path2files = path, \n",
    "                                   image_names = test_image_names, \n",
    "                                   Y = test_labels['has_cell_13'],\n",
    "                                   mean_sd_dict=mean_sd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': test_labels.shape[0], # all validation data\n",
    "          'shuffle': False, 'num_workers' : 1}\n",
    "test_generator = data.DataLoader(test_set, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "test_predictions = np.zeros(test_y.shape)\n",
    "test_values = np.zeros(test_y.shape)\n",
    "with torch.no_grad():\n",
    "    for x, y in test_generator:\n",
    "        x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "        scores = model(x)\n",
    "        _, preds = scores.max(1)\n",
    "        test_values = (y.data).cpu().numpy()\n",
    "        test_predictions = (preds.data).cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(815,)\n",
      "(815,)\n",
      "[0 0 0 1]\n",
      "[1 1 0 1]\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "Name: has_cell_13, dtype: int64\n",
      "0.7705521472392638\n",
      "[[0.28343558 0.0993865 ]\n",
      " [0.13006135 0.48711656]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "savetxt() got an unexpected keyword argument 'delimeter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-336dd20e88c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_set_predictions.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_set_y.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimeter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#import seaborn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#seaborn.heatmap(df_cm, annot=True, cmap = seaborn.color_palette(\"BuGn_r\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: savetxt() got an unexpected keyword argument 'delimeter'"
     ]
    }
   ],
   "source": [
    "print(test_predictions.shape)\n",
    "print(test_values.shape)\n",
    "print(test_predictions[0:4])\n",
    "print(test_values[0:4])\n",
    "print(test_y[0:4])\n",
    "print(sum(test_predictions == test_values)/test_predictions.shape[0]) # accuracy\n",
    "confusion_matrix = np.zeros((2, 2))\n",
    "confusion_matrix[0, 0] = sum(np.logical_and(test_predictions == 0, test_values == 0))/test_predictions.shape[0]\n",
    "confusion_matrix[1, 0] = sum(np.logical_and(test_predictions == 1, test_values == 0))/test_predictions.shape[0]\n",
    "confusion_matrix[0, 1] = sum(np.logical_and(test_predictions == 0, test_values == 1))/test_predictions.shape[0]\n",
    "confusion_matrix[1, 1] = sum(np.logical_and(test_predictions == 1, test_values == 1))/test_predictions.shape[0]\n",
    "print(confusion_matrix)\n",
    "np.savetxt(\"test_set_confusion_matrix.txt\", confusion_matrix, delimiter = '\\t')\n",
    "\n",
    "np.savetxt(\"test_set_predictions.txt\", test_predictions, delimiter = '\\t')\n",
    "np.savetxt(\"test_set_y.txt\", test_values, delimeter = '\\t')\n",
    "#import seaborn\n",
    "#seaborn.heatmap(df_cm, annot=True, cmap = seaborn.color_palette(\"BuGn_r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "def flatten(x):\n",
    "    return x.view(-1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "X = np.zeros((test_labels.shape[0], 3*193*193))\n",
    "for i in range(test_labels.shape[0]):\n",
    "    X[i,] = flatten(test_set.getXimage(i)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 815 samples in 3.318s...\n",
      "[t-SNE] Computed neighbors for 815 samples in 118.524s...\n",
      "[t-SNE] Computed conditional probabilities for sample 815 / 815\n",
      "[t-SNE] Mean sigma: 110.189131\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 69.075996\n",
      "[t-SNE] Error after 300 iterations: 1.045783\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=30, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(815, 2)\n",
      "[[-11.483752   -9.282276 ]\n",
      " [ -7.5917945   6.7265086]\n",
      " [ -5.707936   -2.2783551]\n",
      " [ -8.738314   -8.937672 ]]\n"
     ]
    }
   ],
   "source": [
    "print(tsne_results.shape)\n",
    "print(tsne_results[0:4])\n",
    "np.savetxt('test_set_tsne_embedding.txt', tsne_results, delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
