{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import pandas\n",
    "from dataLoader import OrganoidDataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import sys\n",
    "import pandas\n",
    "from dataLoader import OrganoidDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "params = {'batch_size': 20, # low for testing\n",
    "          'shuffle': True, 'num_workers' : 1}\n",
    "max_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/CS231n_Tim_Shan_example_data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_descriptions = pandas.read_csv('../data/well_summary_A1_e0891BSA_all.csv', sep=',', header=0) # need to change name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well id</th>\n",
       "      <th>day</th>\n",
       "      <th>median pixel intensity</th>\n",
       "      <th>mw_area shape</th>\n",
       "      <th>hyst1 area</th>\n",
       "      <th>hyst2 area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>7830</td>\n",
       "      <td>512</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>8265</td>\n",
       "      <td>3044</td>\n",
       "      <td>3008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>8280</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>8096</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>8544</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   well id  day  median pixel intensity  mw_area shape  hyst1 area  hyst2 area\n",
       "0        0    0                   125.0           7830         512         418\n",
       "1        1    0                   125.0           8265        3044        3008\n",
       "2        2    0                   127.0           8280          30           0\n",
       "3        3    0                   128.0           8096         121           0\n",
       "4        4    0                   128.0           8544          82           0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well_descriptions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "day0wells = well_descriptions[(well_descriptions['day'] == 0)]\n",
    "day13wells = well_descriptions[(well_descriptions['day'] == 13)]\n",
    "finalSizes = day13wells['mw_area shape']\n",
    "well_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f414e586940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalSizes.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4800):\n",
    "  i2str = str(i)\n",
    "  if len(i2str) == 1:\n",
    "    i2str = '000' + i2str\n",
    "  if len(i2str) == 2:\n",
    "    i2str = '00' + i2str\n",
    "  if len(i2str) == 3:\n",
    "    i2str = '0' + i2str\n",
    "  well_labels.append(i2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_train_set = OrganoidDataset(path2files = path, well_labels = well_labels, day_label_X = ['00']*4800, sizes = finalSizes)\n",
    "training_generator = data.DataLoader(initial_train_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NUM_TRAIN = 49000\n",
    "# loader_train = DataLoader(training_generator, batch_size=64, \n",
    "#                           sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 193\n",
    "in_channel = 4\n",
    "output_channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "################################################################################\n",
    "# TODO: Rewrite the 2-layer ConvNet with bias from Part III with the           #\n",
    "# Sequential API.                                                              #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3,out_channels=channel_1,kernel_size=5,padding=2,bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=channel_1,out_channels=channel_2,kernel_size=3,padding=1,bias=True),\n",
    "    nn.ReLU(),   \n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2*image_size*image_size, output_channel,bias=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(max_epochs):\n",
    "#   # Training\n",
    "#   optimizer.zero_grad()\n",
    "#   totalbatchMSE = 0.0\n",
    "#   for local_X, local_Y in training_generator:\n",
    "#     local_X, local_Y = local_X.to(device), local_Y.to(device)\n",
    "#     Y_hat = model.run_all_forward(local_X)\n",
    "#     train_error = loss(Y_hat, local_Y)\n",
    "#     train_error.backward()\n",
    "#     optimizer.step()\n",
    "#     model.eval() # set evaluation mode\n",
    "#     Y_hat = model.run_all_forward(local_X)\n",
    "#     train_error = loss(Y_hat, local_Y).item()\n",
    "#     totalbatchMSE = totalbatchMSE + params['batch_size']*train_error/4800 # rescale train_error\n",
    "#     train_error_array[epoch] = totalbatchMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Traceback (most recent call last):\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\\n    samples = collate_fn([dataset[i] for i in batch_indices])\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\\n    samples = collate_fn([dataset[i] for i in batch_indices])\\n  File \"/home/shanzhou/OrganoidNet/models/dataLoader.py\", line 32, in __getitem__\\n    y = self.getYsize(index)\\n  File \"/home/shanzhou/OrganoidNet/models/dataLoader.py\", line 29, in getYsize\\n    return self.sizes[index]\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\", line 767, in __getitem__\\n    result = self.index.get_value(self, key)\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3118, in get_value\\n    tz=getattr(series.dtype, \\'tz\\', None))\\n  File \"pandas/_libs/index.pyx\", line 106, in pandas._libs.index.IndexEngine.get_value\\n  File \"pandas/_libs/index.pyx\", line 114, in pandas._libs.index.IndexEngine.get_value\\n  File \"pandas/_libs/index.pyx\", line 162, in pandas._libs.index.IndexEngine.get_loc\\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 958, in pandas._libs.hashtable.Int64HashTable.get_item\\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 964, in pandas._libs.hashtable.Int64HashTable.get_item\\nKeyError: 1089\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-57cb6022a1d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotalbatchMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move to device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Traceback (most recent call last):\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\\n    samples = collate_fn([dataset[i] for i in batch_indices])\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\\n    samples = collate_fn([dataset[i] for i in batch_indices])\\n  File \"/home/shanzhou/OrganoidNet/models/dataLoader.py\", line 32, in __getitem__\\n    y = self.getYsize(index)\\n  File \"/home/shanzhou/OrganoidNet/models/dataLoader.py\", line 29, in getYsize\\n    return self.sizes[index]\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\", line 767, in __getitem__\\n    result = self.index.get_value(self, key)\\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3118, in get_value\\n    tz=getattr(series.dtype, \\'tz\\', None))\\n  File \"pandas/_libs/index.pyx\", line 106, in pandas._libs.index.IndexEngine.get_value\\n  File \"pandas/_libs/index.pyx\", line 114, in pandas._libs.index.IndexEngine.get_value\\n  File \"pandas/_libs/index.pyx\", line 162, in pandas._libs.index.IndexEngine.get_loc\\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 958, in pandas._libs.hashtable.Int64HashTable.get_item\\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 964, in pandas._libs.hashtable.Int64HashTable.get_item\\nKeyError: 1089\\n'"
     ]
    }
   ],
   "source": [
    "train_errors = {}\n",
    "for e in range(epochs):\n",
    "    totalbatchMSE = 0.0\n",
    "    for x, y in training_generator:\n",
    "        x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "        Y_hat = model(x)\n",
    "        loss = nn.MSELoss(Y_hat,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        totalbatchMSE = totalbatchMSE + params['batch_size']*train_error/4800\n",
    "        train_errors[e] = totalbatchMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "################################################################################\n",
    "# TODO: Rewrite the 2-layer ConvNet with bias from Part III with the           #\n",
    "# Sequential API.                                                              #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3,out_channels=channel_1,kernel_size=5,padding=2,bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=channel_1,out_channels=channel_2,kernel_size=3,padding=1,bias=True),\n",
    "    nn.ReLU(),   \n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2*32*32, 10,bias=True),\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
